# Robots.txt for Agenxic Website

# Global crawl settings for all crawlers
User-agent: *
Allow: /
Disallow: /admin/
Disallow: /private/
Disallow: /dashboard/
Disallow: /js/
Disallow: /css/

# Sitemaps
Sitemap: https://agenxic.com/sitemap.xml

# AI crawler specific rules
User-agent: GPTBot
Allow: /blog/
Allow: /services/
Allow: /case-studies/
Allow: /about/
Disallow: /contact/
Disallow: /admin/
Disallow: /private/
Disallow: /dashboard/
Disallow: /js/
Disallow: /css/

User-agent: Claude-Bot
Allow: /blog/
Allow: /services/
Allow: /case-studies/
Allow: /about/
Disallow: /contact/
Disallow: /admin/
Disallow: /private/
Disallow: /dashboard/
Disallow: /js/
Disallow: /css/

User-agent: Anthropic-Bot
Allow: /blog/
Allow: /services/
Allow: /case-studies/
Allow: /about/
Disallow: /contact/
Disallow: /admin/
Disallow: /private/
Disallow: /dashboard/
Disallow: /js/
Disallow: /css/

# Major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

# Note: For tags and categories pages that should not be indexed,
# use meta robots tags or HTTP headers on those pages instead of robots.txt